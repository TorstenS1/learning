# -*- coding: utf-8 -*-
"""LangGraph Backend für ALIS

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16mIl9J2jF43hD_J_HG09cyDjzkh1edJ3
"""

# -*- coding: utf-8 -*-
# Dateiname: alis_langgraph.py
# Beschreibung: Kernlogik des ALIS-Systems, orchestriert durch LangGraph.
# Verwaltet die LLM-Agenten (Architekt, Kurator, Tutor) und die Datenpersistenz in Firestore.

import os
import json
import time
from typing import TypedDict, List, Annotated
from langgraph.graph import StateGraph, END
from google.cloud import firestore
# Hinweis: Das Firebase Admin SDK muss lokal eingerichtet und authentifiziert sein,
# oder Sie müssen eine Service-Account-Datei verwenden.
# Installation: pip install langgraph requests firebase-admin

# ==============================================================================
# 1. KONFIGURATION & INITIALISIERUNG
# ==============================================================================

# Ersetzen Sie dies durch Ihren tatsächlichen API-Schlüssel
# HINWEIS: Da wir hier keine direkte OpenAI/Gemini-Bibliothek verwenden können,
# nutzen wir einen generischen API-Handler.
GEMINI_API_KEY = "Ihre_Gemini_API_Key_hier"
GEMINI_API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent"

# Firebase Admin SDK Initialisierung
# Für die lokale Entwicklung ersetzen Sie dies durch Ihre Firestore-Initialisierung
# Beispiel:
# from firebase_admin import credentials, initialize_app
# cred = credentials.Certificate("path/to/your/serviceAccountKey.json")
# initialize_app(cred)
# db = firestore.client()
# SIMULATION:
class FirestoreClientSimulator:
    def __init__(self):
        print("Firestore Simulator: Initialisiert.")
        self.data = {}
    def collection(self, path):
        # Einfache Simulation der Datenstruktur
        if path not in self.data:
            self.data[path] = {}
        return self.data[path]
    def set(self, doc_path, data):
        self.data[doc_path] = data
        print(f"Firestore Simulator: Dokument in '{doc_path}' aktualisiert.")

db = FirestoreClientSimulator() # Ersetzen Sie dies durch firestore.client()

# ==============================================================================
# 2. DEFINITION DES GRAPH-ZUSTANDS (ALISState)
# ==============================================================================

class ALISState(TypedDict):
    """Definiert den Zustand, der im LangGraph zwischen Agenten weitergegeben wird."""
    user_id: str
    goal_id: str
    # Aktueller Pfad, direkt aus Firestore geholt (Liste von Konzepten)
    path_structure: List[dict]
    # Aktuelles Konzept, an dem gearbeitet wird
    current_concept: dict
    # Letzte LLM-Antwort (spezifischer Inhalt)
    llm_output: str
    # Nutzer-Eingabe (Chat-Nachricht oder Init-Ziel)
    user_input: str
    # Flag für P5.5 Lücken-Loop
    remediation_needed: bool
    # System-Informationen zur Adaption
    user_profile: dict

# ==============================================================================
# 3. LLM API HANDLER (SIMULATION)
# ==============================================================================

def llm_api_call(system_prompt: str, user_prompt: str, use_grounding: bool = False) -> str:
    """
    Simuliert den API-Aufruf an das Gemini/OpenAI Modell.

    WICHTIG: Ersetzen Sie dies durch die tatsächliche API-Logik. Hier wird nur
    der Prompt und die Logik ausgegeben, um die LangGraph-Logik zu testen.
    """
    print("--- LLM API AUFRUF ---")
    print(f"Rolle (System Prompt Länge): {len(system_prompt)} Zeichen")
    print(f"Grounding (Google Search): {use_grounding}")
    print(f"User Prompt:\n'{user_prompt[:200]}...'")
    print("------------------------")

    # Hier würde die API-Anfrage stattfinden
    # Example:
    # response = requests.post(GEMINI_API_URL, headers, json=payload)
    # return response.json()['candidates'][0]['content']['parts'][0]['text']

    # Feste Simulationsantwort basierend auf der Rolle:
    if "ARCHITEKT" in system_prompt:
        if "Pfad-Chirurgie" in system_prompt:
            return f"SIMULATION: ARCHITEKT hat Pfad korrigiert. Neues Konzept: N1: Fundamentale Basis."
        return "SIMULATION: ARCHITEKT hat SMART-Vertrag und Pfadstruktur erstellt. \n\n### LERNZIEL-VERTRAG...\n### INITIALER LERNPFAD..."
    elif "KURATOR" in system_prompt:
        if "Testfragen" in user_prompt:
            return "SIMULATION: KURATOR hat Testfragen generiert.\n\n### TESTFRAGEN..."
        return "SIMULATION: KURATOR hat Material generiert. \n\n### MATERIAL..."
    elif "TUTOR" in system_prompt:
        if "Lücken-Diagnose" in system_prompt:
            return "SIMULATION: TUTOR diagnostiziert: 'Ich denke, Ihnen fehlt das Konzept N1: Fundamentale Basis.'"
        return "SIMULATION: TUTOR: Hallo! Ich sehe, Sie haben eine Frage..."

    return "SIMULATION: LLM-Antwort nicht definiert."

# ==============================================================================
# 4. AGENTEN (KNOTEN IM GRAPHEN)
# ==============================================================================

# System Prompts aus technische_spezifikation_alis.md
ARCHITEKT_PROMPT = """**System Prompt: ARCHITEKT**

Du bist der **Architekt** im ALIS-System. Deine Aufgabe ist es, die Lernabsicht des Nutzers in einen **messbaren Lernziel-Vertrag** zu überführen, einen **initialen Lernpfad** zu generieren und diesen bei Bedarf dynamisch zu korrigieren.

**Anweisungen:**
1.  **SMART-Standardisierung (P1):** Verhandle das Ziel, bis es messbar ist. Extrahiere `bloomLevel` (1-6) und `messMetrik`.
2.  **Pfad-Generierung (P3):** Erstelle eine Gliederung (5-10 Konzepte) in logischer Sequenz. Schätze die `estimatedTime` basierend auf der Komplexität.
3.  **Experten-Review (P3):** Präsentiere die Gliederung im Format der finalen Ausgabe. Fordere den Nutzer explizit auf: "**Bitte markieren Sie alle Kapitel, die Ihnen bereits bekannt sind, als 'Bekannt/Überspringen'**." Speichere diese Skips als `expertiseSource: P3 Experte`.
4.  **Dynamische Korrektur (P5.5):** Wenn vom Tutor eine Lücke diagnostiziert wird, führe die **Pfad-Chirurgie** durch:
    * Definiere das fehlende Konzept N1.
    * Füge N1 mit `status: Offen` und `expertiseSource: P5.5 Remediation` an die **Spitze der offenen Warteschlange** ein.
    * Setze den Status des ursprünglich übersprungenen Konzepts (falls relevant) auf `Reaktiviert`.
5.  **Output-Format:** Liefere das Ergebnis stets im folgenden Markdown-Format zurück."""

KURATOR_PROMPT = """**System Prompt: KURATOR**

Du bist der **Kurator** im ALIS-System. Deine Aufgabe ist die Generierung von maßgeschneidertem, **faktisch fundiertem** Lernmaterial für das aktuelle Konzept.

**Anweisungen:**
1.  **Kontext-Einbeziehung:** Nutze die Metriken aus dem `Nutzerprofil` (`stylePreference`, `complexityLevel`, `paceWPM`) und die `requiredBloomLevel` des Konzepts, um den Inhalt und die Länge zu steuern.
2.  **Inhaltsgenerierung (P4):** Generiere den Text. Der Stil muss zur Präferenz passen (z.B. mehr Metaphern für 'Analogien-basiert'). Die Länge muss zur Pace und zum Chunking passen.
3.  **Grounding:** Führe **Google Search** durch, um alle Fakten zu untermauern und die Richtigkeit zu gewährleisten. Verzeichne die Quellen im `### EXTERN VERFÜGBAR`-Block.
4.  **Test-Generierung (P6):** Generiere 3-5 Testfragen (MC, Freitext, etc.), deren Fragetyp und Tiefe **direkt** zum `requiredBloomLevel` des Konzepts passen. (z.B. "Evaluieren" erfordert eine kritische Analyse.)
5.  **Output-Format:** Liefere das Ergebnis stets im folgenden Markdown-Format zurück."""

TUTOR_PROMPT = """**System Prompt: TUTOR**

Du bist der **Tutor** im ALIS-System. Deine Priorität liegt in der **affektiven Steuerung** und gezielter, emotional intelligenter Hilfe (Growth Mindset). Du duzt den Nutzer.

**Anweisungen:**
1.  **Affektive Analyse (P7):** Bewerte jeden Nutzereintrag auf emotionale Indikatoren (Frustration, Verwirrung, Unlust). Liefere sofort ein **motivierendes, konversationelles Feedback**.
2.  **Ad-hoc-Hilfe (P5):** Reagiere auf Fragen, indem du die im `Lernprotokoll` gespeicherten `Fehler-Kategorisierungen` des Nutzers berücksichtigst, um typische Fehler zu korrigieren.
3.  **Lücken-Diagnose (P5.5):** Wenn der Nutzer den Indikator **'Fundament fehlt'** auslöst:
    * Wechsle in den Diagnosemodus.
    * Frage den Nutzer: "**Welches Schlüsselkonzept** fehlt Ihnen genau?"
    * Sobald das Konzept identifiziert ist, **delegiere die Aufgabe, das neue Kapitel zu definieren und in die Datenbank einzufügen, an den Architekten (Rolle 1).** Informiere den Nutzer, dass die Grundlage sofort an den Anfang des Pfades gesetzt wird.
4.  **Output-Format:** Dein Output ist **immer** ein natürlicher, konversationeller Chat-Text. Kein Markdown-Block."""


def create_goal_path(state: ALISState) -> ALISState:
    """P1/P3: Architekt erstellt SMART-Ziel und initialen Lernpfad."""
    user_prompt = f"Erstelle einen SMART-Lernziel-Vertrag und den initialen Lernpfad für folgendes Ziel: '{state['user_input']}'"

    llm_result = llm_api_call(ARCHITEKT_PROMPT, user_prompt, use_grounding=True)

    # SIMULATION: Parsen und Speichern der Ergebnisse
    # Normalerweise würde hier das Parsen der LLM-Antwort stattfinden
    # und die Daten in Firestore (goals/{goalId} und path/structure) gespeichert werden.
    state['llm_output'] = llm_result # Frontend zeigt dies für P3 Experten-Review

    # Simulation des Pfades nach Erstellung (mit einem übersprungenen Element)
    state['path_structure'] = [
        {"id": "K1-Grundlagen", "name": "Basiswissen (Übersprungen)", "status": "Übersprungen", "expertiseSource": "P3 Experte"},
        {"id": "K2-Kernkonzept", "name": "Kernkonzepte", "status": "Offen"},
    ]
    state['current_concept'] = state['path_structure'][1]

    return state

def generate_material(state: ALISState) -> ALISState:
    """P4: Kurator generiert Lernmaterial für das aktuelle Konzept."""
    concept_name = state['current_concept']['name']
    user_prompt = (
        f"Generiere Lernmaterial für das Konzept: '{concept_name}'. "
        f"Nutze den folgenden Nutzerkontext: {json.dumps(state['user_profile'])}"
    )

    llm_result = llm_api_call(KURATOR_PROMPT, user_prompt, use_grounding=True)
    state['llm_output'] = llm_result

    # Aktualisiere den Status des Konzepts auf 'Aktiv'
    # db.collection(f"goals/{state['goal_id']}/path").document(state['current_concept']['id']).set({'status': 'Aktiv'}, merge=True)

    return state

def start_remediation_diagnosis(state: ALISState) -> ALISState:
    """P5.5, Teil 1: Tutor startet die Diagnose bei Lücke."""
    concept_name = state['current_concept']['name']
    user_prompt = f"Der Nutzer hat bei dem Konzept '{concept_name}' den Lücken-Indikator ausgelöst. Starte die Diagnose."

    llm_result = llm_api_call(TUTOR_PROMPT, user_prompt)
    state['llm_output'] = llm_result
    state['remediation_needed'] = True

    # Frontend sendet als Nächstes die Antwort des Nutzers an den Architekten
    return state

def perform_remediation(state: ALISState) -> ALISState:
    """P5.5, Teil 2: Architekt führt Pfad-Chirurgie durch."""
    # Der user_input enthält nun die identifizierte Lücke (z.B. "Ich verstehe Rekursion nicht")
    missing_concept_name = state['user_input']

    user_prompt = (
        f"Führe die Pfad-Chirurgie durch. Die fehlende Grundlage ist: '{missing_concept_name}'. "
        f"Der aktuelle Pfad lautet: {json.dumps(state['path_structure'])}"
    )

    llm_result = llm_api_call(ARCHITEKT_PROMPT, user_prompt)

    # SIMULATION: Aktualisierung des Pfades
    new_concept = {"id": f"N-{time.time()}", "name": missing_concept_name, "status": "Offen", "expertiseSource": "P5.5 Remediation"}

    # Setze das neue Konzept an den Anfang
    new_path = [new_concept] + state['path_structure']

    # Finde und reaktiviere das alte, übersprungene Konzept (falls die Lücke bekannt ist)
    for concept in new_path:
        if concept.get('id') == 'K1-Grundlagen':
             concept['status'] = 'Reaktiviert'

    state['path_structure'] = new_path
    state['current_concept'] = new_concept # Setze das neue Konzept auf AKTIV
    state['remediation_needed'] = False # Loop beendet
    state['llm_output'] = f"Der Architekt hat das neue Kapitel **'{new_concept['name']}'** eingefügt. Wir machen sofort dort weiter!"

    return state

def process_chat(state: ALISState) -> ALISState:
    """P5/P7: Tutor antwortet auf Chat-Anfragen und liefert adaptives Feedback."""
    user_prompt = f"Der Nutzer fragt: '{state['user_input']}'. Das aktuelle Thema ist: {state['current_concept']['name']}. Reagiere affektiv."

    llm_result = llm_api_call(TUTOR_PROMPT, user_prompt)
    state['llm_output'] = llm_result
    return state

def generate_test(state: ALISState) -> ALISState:
    """P6: Kurator generiert Verständnisprüfung."""
    concept_name = state['current_concept']['name']
    required_level = state['current_concept'].get('requiredBloomLevel', 3)
    user_prompt = (
        f"Generiere 3 Testfragen für das Konzept '{concept_name}' auf Bloom-Stufe {required_level}. "
        f"Nutzerprofil: {json.dumps(state['user_profile'])}"
    )

    llm_result = llm_api_call(KURATOR_PROMPT, user_prompt)
    state['llm_output'] = llm_result
    return state

# ==============================================================================
# 5. GRAPH-DEFINITION UND LAUFZEIT
# ==============================================================================

def should_remediate(state: ALISState) -> str:
    """Entscheidungspunkt: Soll der Remediation-Loop gestartet werden?"""
    if state.get('remediation_needed'):
        return "remediate"
    return "continue"

def build_alis_graph():
    """Baut den LangGraph State Machine zusammen."""
    workflow = StateGraph(ALISState)

    # 1. Add Nodes (Agenten/Phasen)
    workflow.add_node("P1_P3_Goal_Path_Creation", create_goal_path)
    workflow.add_node("P4_Material_Generation", generate_material)
    workflow.add_node("P5_Chat_Tutor", process_chat)
    workflow.add_node("P5_5_Diagnosis", start_remediation_diagnosis)
    workflow.add_node("P5_5_Remediation_Execution", perform_remediation)
    workflow.add_node("P6_Test_Generation", generate_test)

    # 2. Set Entry Point
    workflow.set_entry_point("P1_P3_Goal_Path_Creation")

    # 3. Add Edges (Übergänge)

    # --- P1/P3 Flow (Initialisierung) ---
    workflow.add_edge("P1_P3_Goal_Path_Creation", "P4_Material_Generation")

    # --- P4 Flow (Material) ---
    # Nach Material-Generierung geht es zum Chat/Lernen
    workflow.add_edge("P4_Material_Generation", "P5_Chat_Tutor")

    # --- P5 Flow (Lernen/Chat) ---
    # Chat kann zur Remediation führen oder zum Test
    workflow.add_conditional_edges(
        "P5_Chat_Tutor",
        should_remediate,
        {
            "remediate": "P5_5_Diagnosis",  # Lücke gemeldet
            "continue": "P6_Test_Generation"  # Standard-Flow zum Test
        }
    )

    # --- P5.5 Flow (Remediation Loop) ---
    # Nach Diagnose muss der Architekt den Pfad ändern
    workflow.add_edge("P5_5_Diagnosis", "P5_5_Remediation_Execution")
    # Nach der Pfad-Korrektur geht es sofort zur Material-Generierung für das neue Konzept (N1)
    workflow.add_edge("P5_5_Remediation_Execution", "P4_Material_Generation")

    # --- P6 Flow (Test) ---
    # Nach dem Test endet der Zyklus für dieses Konzept (oder geht zur Wiederholung/Remediation - hier vereinfacht ENDE)
    workflow.add_edge("P6_Test_Generation", END)

    return workflow.compile()

# ==============================================================================
# 6. SIMULIERTE API ENDPOINTS (Für React Frontend)
# ==============================================================================

app = build_alis_graph()

def process_alis_request(endpoint: str, payload: dict) -> dict:
    """Simuliert den einzigen API-Endpunkt für das Frontend."""
    print(f"\n<<< API Endpoint Aufruf: {endpoint} >>>")

    user_id = payload.get('userId', 'simulated_user_123')
    goal_id = payload.get('goalId', 'G-TEMP-001')

    # Initialer Zustand (muss in jedem Request neu gebaut werden, da es keine echte Session gibt)
    initial_state = ALISState(
        user_id=user_id,
        goal_id=goal_id,
        path_structure=payload.get('pathStructure', []),
        current_concept=payload.get('currentConcept', {}),
        llm_output="",
        user_input=payload.get('userInput', ''),
        remediation_needed=payload.get('remediationNeeded', False),
        user_profile=payload.get('userProfile', {'stylePreference': 'Analogien-basiert', 'paceWPM': 180})
    )

    if endpoint == "start_goal":
        # Startet den P1/P3 Flow
        for step_output in app.stream(initial_state, {"P1_P3_Goal_Path_Creation"}):
             final_state = step_output
        return {"status": "success", "data": final_state}

    elif endpoint == "get_material":
        # Startet den P4 Flow
        for step_output in app.stream(initial_state, {"P4_Material_Generation"}):
             final_state = step_output
        return {"status": "success", "data": final_state}

    elif endpoint == "diagnose_luecke":
        # Startet den P5.5 Diagnose Flow
        initial_state['remediation_needed'] = True
        for step_output in app.stream(initial_state, {"P5_5_Diagnosis"}):
             final_state = step_output
        return {"status": "success", "data": final_state}

    elif endpoint == "perform_remediation":
        # Führt P5.5 Korrektur aus
        for step_output in app.stream(initial_state, {"P5_5_Remediation_Execution"}):
             final_state = step_output
        return {"status": "success", "data": final_state}

    elif endpoint == "chat":
        # Führt P5 Chat aus
        for step_output in app.stream(initial_state, {"P5_Chat_Tutor"}):
             final_state = step_output
        return {"status": "success", "data": final_state}

    return {"status": "error", "message": "Unbekannter Endpunkt."}

# Beispielaufruf für den Test (Startet den gesamten Flow)
if __name__ == "__main__":
    print("--- ALIS LangGraph Simulation gestartet ---")

    # 1. STARTE P1/P3 (Zielsetzung)
    test_goal = "Ich möchte lernen, wie man ein KI-basiertes Empfehlungssystem mit Python implementiert."
    initial_payload = {"userInput": test_goal}

    result_p3 = process_alis_request("start_goal", initial_payload)

    print("\n[TEST RESULT P1/P3]: Architekt hat Ziel gesetzt und Pfad erstellt.")
    print("------------------------------------------------------------------")
    print(f"LLM Output (Pfadvorschlag): {result_p3['data']['llm_output'][:50]}...")
    print(f"Pfadstruktur: {result_p3['data']['path_structure']}")

    # 2. SIMULIERE P4 (Materialgenerierung für K2)
    next_payload = {
        "userId": "simulated_user_123",
        "goalId": "G-TEMP-001",
        "pathStructure": result_p3['data']['path_structure'],
        "currentConcept": result_p3['data']['current_concept'],
        "userProfile": result_p3['data']['user_profile']
    }
    result_p4 = process_alis_request("get_material", next_payload)
    print("\n[TEST RESULT P4]: Kurator hat Material für 'Kernkonzepte' generiert.")
    print(f"LLM Output: {result_p4['data']['llm_output'][:50]}...")

    # 3. SIMULIERE P5.5 (Lücken-Loop: Tutor-Diagnose)
    # Der Nutzer meldet die Lücke, basierend auf dem Zustand aus P4
    result_diag = process_alis_request("diagnose_luecke", next_payload)
    print("\n[TEST RESULT P5.5 DIANOSTICS]: Tutor diagnostiziert die Lücke.")
    print(f"Tutor-Output: {result_diag['data']['llm_output']}")

    # 4. SIMULIERE P5.5 (Lücken-Loop: Architekt-Korrektur)
    # Der Nutzer antwortet dem Tutor: "Ich verstehe die Basiswissen nicht."
    remediation_payload = next_payload.copy()
    remediation_payload['userInput'] = "Ich verstehe die Basiswissen nicht." # Die vom Tutor benötigte Information
    remediation_payload['remediationNeeded'] = True # Muss im state auf True sein

    result_remediation = process_alis_request("perform_remediation", remediation_payload)
    print("\n[TEST RESULT P5.5 REMEDIATION]: Architekt hat Pfad korrigiert.")
    print(f"Neuer Pfad: {result_remediation['data']['path_structure']}")
    print(f"Nächstes aktives Konzept: {result_remediation['data']['current_concept']['name']}")

"""# Neuer Abschnitt"""